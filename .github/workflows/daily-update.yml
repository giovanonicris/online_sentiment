name: Daily Data Update with Refresh Log

on:
  schedule:
    - cron: '0 7 * * *'  # runs at 3am
  workflow_dispatch:
    inputs:
      run_job:
        description: 'Which job to run'
        required: true
        default: 'all'
        type: choice
        options:
          - all
          - enterprise
          - emerging

jobs:
  process-data:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
        with:
          token: ${{ secrets.PERSONAL_ACCESS_TOKEN }}

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Cache dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}

      - name: Install requirements
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install lxml[html_clean]

      - name: Run Enterprise Risk News script
        if: ${{ github.event.inputs.run_job == 'all' || github.event.inputs.run_job == 'enterprise' || github.event.inputs.run_job == '' }}
        run: python EnterpriseRiskNews.py

      - name: Run Emerging Risk News script
        if: ${{ github.event.inputs.run_job == 'all' || github.event.inputs.run_job == 'emerging' || github.event.inputs.run_job == '' }}
        run: python EmergingRiskNews.py

      - name: Debug filesystem
        run: |
          echo "****FILESYSTEM DEBUG ******"
          pwd
          echo "repo root contains: "
          ls -la
          echo "output directory contains:"
          ls -la output/ || echo "output/ directory does not exist"
          echo "ALL CSVS in repo:"
          find . -name "*.csv" -type f
          echo "CSV sizes:"
          find output/ -name "*.csv" -type f -exec ls -lh {} \;
          echo "*******************************"

      - name: Compress CSVs
        run: |
          for file in output/*.csv; do
            gzip "$file" || echo "No CSVs to compress or error occurred"
          done

      - name: Upload compressed artifacts
        uses: actions/upload-artifact@v3
        with:
          name: compressed-data
          path: output/*.csv.gz

  publish-data:
    needs: process-data
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
        with:
          token: ${{ secrets.PERSONAL_ACCESS_TOKEN }}
          ref: data  # Check out the data branch

      - name: Download compressed artifacts
        uses: actions/download-artifact@v3
        with:
          name: compressed-data
          path: output/

      - name: Decompress CSVs
        run: |
          for file in output/*.csv.gz; do
            gunzip -c "$file" > "${file%.gz}" || echo "Error decompressing $file"
          done

      - name: Commit and push CSVs to data branch
        run: |
          git config --global user.name "github-actions"
          git config --global user.email "github-actions@users.noreply.github.com"
          git checkout -b data || git checkout data
          mkdir -p output
          mv output/*.csv output/ || echo "No CSVs to move"
          git add output/*.csv
          if git diff --cached --quiet; then
            echo "No changes detected in the CSV files"
          else
            echo "Changes detected, committing..."
            git commit -m "Update Enterprise and Emerging Risk CSVs - $(date '+%Y-%m-%d %H:%M:%S')"
            git push origin data --force
          fi

      - name: Debug final state
        run: |
          echo "****FINAL STATE DEBUG ******"
          echo "output directory contains:"
          ls -la output/
          echo "*******************************"
